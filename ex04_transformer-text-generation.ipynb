{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a5b35dc-65cc-45c9-a598-05d523dcb1a8",
   "metadata": {},
   "source": [
    "The codes are adpated from https://github.com/karpathy/nanoGPT/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef6e277-3645-4a6b-880b-9106214ac438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from typing import Final\n",
    "import math\n",
    "# \n",
    "import numpy as np\n",
    "# torch\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import (\n",
    "    IterableDataset,\n",
    "    DataLoader,\n",
    ")\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.nn.utils import clip_grad_norm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2561f81c-9c5c-4848-9986-f740c67ad9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyShakespeareDataset(IterableDataset):\n",
    "\n",
    "    DATA_URL = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "\n",
    "    TEXT_FILENAME = 'input.txt'\n",
    "    TRAIN_SET_FILENAME = 'train.pt'\n",
    "    VAL_SET_FILENAME = 'val.pt'\n",
    "    METADATA_FILENAME = 'metadata.json'\n",
    "\n",
    "    START_TOKEN: Final[str] = '\\n'\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        root: Path,\n",
    "        block_size: int,\n",
    "        train: bool,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if not root.exists():\n",
    "            self.download(root)\n",
    "\n",
    "        path = root / (self.TRAIN_SET_FILENAME if train else self.VAL_SET_FILENAME)\n",
    "        \n",
    "\n",
    "        self.data = torch.load(path, weights_only=True)\n",
    "        self.block_size = block_size\n",
    "\n",
    "\n",
    "        metadata_path = root / self.METADATA_FILENAME\n",
    "        with open(metadata_path, 'r') as stream:\n",
    "            char_to_idx = json.load(stream)\n",
    "        \n",
    "        self.char_to_idx = char_to_idx\n",
    "        self.idx_to_char = {idx: char for char, idx in self.char_to_idx.items()}\n",
    "        self.vocab_size = len(self.char_to_idx)\n",
    "\n",
    "    \n",
    "    def __iter__(self):\n",
    "        start_high = len(self.data) - block_size\n",
    "        \n",
    "        while True:\n",
    "            start = torch.randint(high=start_high, size=(1, ))[0]\n",
    "            stop = start + self.block_size\n",
    "            x = self.data[start: stop]\n",
    "            y = self.data[start + 1: stop + 1]\n",
    "            yield x, y\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def download(cls, root: Path):\n",
    "        if not root.exists():\n",
    "            root.mkdir(parents=True)\n",
    "        \n",
    "        text = requests.get(cls.DATA_URL).text\n",
    "        \n",
    "        with open((root / cls.TEXT_FILENAME), 'w') as stream:\n",
    "            stream.write(text)\n",
    "\n",
    "        # metadata\n",
    "        char_set = sorted(list(set(text)))\n",
    "        char_to_idx = {char: idx for idx, char in enumerate(char_set)}\n",
    "\n",
    "        dataset = cls.encode(text, char_to_idx)\n",
    "        dataset = torch.tensor(dataset, dtype=torch.int64)\n",
    "        \n",
    "        train_stop = int(0.9 * len(dataset))\n",
    "        train_set = dataset[:train_stop]\n",
    "        val_set = dataset[train_stop:]\n",
    "\n",
    "        # \n",
    "        torch.save(train_set, root / cls.TRAIN_SET_FILENAME)\n",
    "        torch.save(val_set, root / cls.VAL_SET_FILENAME)\n",
    "\n",
    "        # save metadata\n",
    "        metadata_path = root / cls.METADATA_FILENAME\n",
    "        with open(metadata_path, 'w') as stream:\n",
    "            json.dump(char_to_idx, stream, indent=4)\n",
    "\n",
    "    @classmethod\n",
    "    def _encode(cls, char_list: str | list[str], char_to_idx) -> list[int]:\n",
    "        return [char_to_idx[char] for char in char_list]\n",
    "\n",
    "    def encode(self, char_list: str | list[str]):\n",
    "        return self._encode(char_list, self.char_to_idx)\n",
    "\n",
    "    @classmethod\n",
    "    def _decode(cls, idx_list: list[int], idx_to_char: dict[int, str]) -> list[str]:\n",
    "        return [idx_to_char[idx] for idx in idx_list]\n",
    "\n",
    "    def decode(self, idx_list: list[int]):\n",
    "        return self._decode(idx_list, self.idx_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5664b8-5aba-4d6e-acd7-0c9f83fe1dbd",
   "metadata": {},
   "source": [
    "# Model & Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ab0dbe-77a7-478f-b56a-1d3882ffd840",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(nn.Module):\n",
    "    \"\"\"scaled dot product attention\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int,\n",
    "        num_heads: int,\n",
    "        bias: bool,\n",
    "        dropout: float,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        assert embed_dim % num_heads == 0\n",
    "\n",
    "        #\n",
    "        self.query_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.key_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.value_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        # output projection\n",
    "        self.output_projection = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        # regularization\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        self.output_dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dropout = dropout\n",
    "        \n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        target: Tensor,\n",
    "        source: Tensor,\n",
    "        attn_mask: Tensor,\n",
    "    ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            target:\n",
    "            source:\n",
    "            attn_mask:\n",
    "        Returns:\n",
    "            ...\n",
    "        \"\"\"\n",
    "        # N: batch size, T: target sequence length, C: embedding dimensionality\n",
    "        N, T, E = target.size()\n",
    "        # S: source sequence length\n",
    "        S = source.size(1)\n",
    "        H = self.num_heads\n",
    "        # depth\n",
    "        D = E // H\n",
    "\n",
    "        scale = 1.0 / math.sqrt(D)\n",
    "\n",
    "        q  = self.query_proj(target)\n",
    "        k  = self.key_proj(source)\n",
    "        v  = self.value_proj(source)\n",
    "\n",
    "        q = q.view(N, T, H, D).transpose(1, 2) # (N, H, T, D)\n",
    "        k = k.view(N, S, H, D).transpose(1, 2) # (N, H, S, D)\n",
    "        v = v.view(N, S, H, D).transpose(1, 2) # (N, H, S, D)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * scale\n",
    "        attn = attn.masked_fill(\n",
    "            mask=attn_mask, \n",
    "            value=float('-inf'),\n",
    "        )\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_dropout(attn)\n",
    "        y = attn @ v\n",
    "        y = y.transpose(1, 2).contiguous().view(N, T, E)\n",
    "\n",
    "        # output projection\n",
    "        y = self.output_projection(y)\n",
    "        y = self.output_dropout(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08790e9d-3590-4549-a2ea-92b1449820f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(CrossAttention):\n",
    "\n",
    "    def forward(self, input: Tensor, attn_mask: Tensor) -> Tensor:\n",
    "        return super().forward(source=input, target=input, attn_mask=attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2041213e-f785-40e8-9122-a49c1e12ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Sequential):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        embed_dim: int,\n",
    "        bias: bool,\n",
    "        dropout: float,\n",
    "        widening_factor: int = 4,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        hidden_dim = 4 * embed_dim\n",
    "        \n",
    "        super().__init__(\n",
    "            nn.Linear(\n",
    "                in_features=embed_dim, \n",
    "                out_features=hidden_dim, \n",
    "                bias=bias\n",
    "            ),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(\n",
    "                in_features=hidden_dim, \n",
    "                out_features=embed_dim, \n",
    "                bias=bias\n",
    "            ),\n",
    "            nn.Dropout(p=dropout),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b46a3d7f-3efa-4ca4-a630-cd37c1a74c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int,\n",
    "        bias: bool,\n",
    "        dropout: float,\n",
    "        widening_factor: int,\n",
    "        num_heads: int,\n",
    "        block_size: int,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(\n",
    "            normalized_shape=embed_dim, \n",
    "            bias=bias,\n",
    "        )\n",
    "        self.attn = SelfAttention(\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            bias=bias,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.ln_2 = nn.LayerNorm(\n",
    "            normalized_shape=embed_dim, \n",
    "            bias=bias,\n",
    "        )\n",
    "        self.mlp = MLP(\n",
    "            embed_dim=embed_dim,\n",
    "            bias=bias,\n",
    "            dropout=dropout,\n",
    "            widening_factor=widening_factor,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        attn_mask: Tensor,\n",
    "    ):\n",
    "        x = x + self.attn(self.ln_1(x), attn_mask=attn_mask)\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c25c1b7e-25ac-44b2-ab40-79eef57c4878",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PicoGPT(nn.Module):\n",
    "\n",
    "    causal_mask: Tensor\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embed_dim: int,\n",
    "        num_heads: int,\n",
    "        block_size: int,\n",
    "        dropout: float,\n",
    "        num_layers: int,\n",
    "        bias: bool,\n",
    "        widening_factor: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block_size = block_size\n",
    "        \n",
    "\n",
    "        block_config = dict(\n",
    "            embed_dim=embed_dim,\n",
    "            bias=bias,\n",
    "            dropout=dropout,\n",
    "            num_heads=num_heads,\n",
    "            block_size=block_size,\n",
    "            widening_factor=widening_factor,\n",
    "        )\n",
    "\n",
    "        \n",
    "        # transformer\n",
    "        self.token_embedder = nn.Embedding(\n",
    "            num_embeddings=vocab_size, \n",
    "            embedding_dim=embed_dim,\n",
    "        )\n",
    "        self.position_embedder = nn.Embedding(\n",
    "            num_embeddings=block_size, \n",
    "            embedding_dim=embed_dim,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.block_list = nn.ModuleList([Block(**block_config) for _ in range(num_layers)])\n",
    "\n",
    "        # token prediction head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(\n",
    "                normalized_shape=embed_dim, \n",
    "                bias=bias,\n",
    "            ),\n",
    "            nn.Linear(\n",
    "                in_features=embed_dim, \n",
    "                out_features=vocab_size, \n",
    "                bias=False,\n",
    "            ),\n",
    "        )\n",
    "        # NOTE: https://paperswithcode.com/method/weight-tying\n",
    "        self.token_embedder.weight = self.head[1].weight \n",
    "\n",
    "        self.register_buffer(\n",
    "            name='causal_mask',\n",
    "            tensor=torch.ones(1, 1, block_size, block_size, dtype=torch.int8).tril().eq(0),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        input: Tensor, \n",
    "        target: Tensor | None = None,\n",
    "    ) -> tuple[Tensor, Tensor | None]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input (Tensor): input tokens\n",
    "            target (Tensor or None): target tokens\n",
    "        Returns:\n",
    "            logits:\n",
    "            loss: (Tensor or None)\n",
    "        \"\"\"\n",
    "        # N: batch size, L: max length in a batch\n",
    "        N, L = input.size()\n",
    "        device = input.device\n",
    "\n",
    "        position = torch.arange(0, L, dtype=torch.int64, device=input.device)\n",
    "        attn_mask = self.causal_mask[..., :L, :L]\n",
    "\n",
    "        token_embed = self.token_embedder(input)\n",
    "        position_embed = self.position_embedder(position)\n",
    "        embed = token_embed + position_embed\n",
    "        embed = self.dropout(embed)\n",
    "\n",
    "        for block in self.block_list:\n",
    "            embed = block(embed, attn_mask=attn_mask)\n",
    "\n",
    "        if target is not None:\n",
    "            # training\n",
    "            logits = self.head(embed)\n",
    "            loss = F.cross_entropy(\n",
    "                logits.view(-1, logits.size(-1)), \n",
    "                target.view(-1), \n",
    "                ignore_index=-1,\n",
    "            )\n",
    "        else:\n",
    "            # inferences\n",
    "            # NOTE: using list [-1] to preserve the time dim\n",
    "            logits = self.head(embed[:, [-1], :])\n",
    "            loss = None\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx: Tensor | None, max_new_tokens, temperature=1.0, top_k=None):        \n",
    "        for _ in range(max_new_tokens):\n",
    "            # if the sequence context is growing too long we must crop it at block_sizes\n",
    "            idx_cond = idx if idx.size(1) <= self.block_size else idx[:, -self.block_size:]\n",
    "            # forward the model to get the logits for the index in the sequence\n",
    "            logits, _ = self(idx_cond)\n",
    "            # pluck the logits at the final step and scale by desired temperature\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            # optionally crop the logits to only the top k options\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            # apply softmax to convert logits to (normalized) probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # append sampled index to the running sequence and continue\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1597866-a2b9-481b-965b-cfdbeddb1888",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c150da3-ffc2-4731-b8ee-e3c2dded1be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "block_size = 256\n",
    "batch_size = 64\n",
    "grad_clip_value = 1\n",
    "embed_dim = 384\n",
    "num_heads = 6\n",
    "num_layers = 6\n",
    "bias = False\n",
    "widening_factor = 4\n",
    "dropout = 0\n",
    "\n",
    "# optimizer\n",
    "lr = 3.0e-4\n",
    "betas = (0.9, 0.99)\n",
    "\n",
    "# training\n",
    "max_training_steps = 5_000\n",
    "val_interval = 250\n",
    "num_val_batches = 200\n",
    "\n",
    "# sampling\n",
    "max_new_tokens = 500\n",
    "temperature = 0.8\n",
    "top_k = 200\n",
    "\n",
    "# system\n",
    "dataset_root = Path('./data')\n",
    "device = torch.device('cuda:1')\n",
    "seed = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67988da0-28fd-4720-9bb4-dfbbe0c0057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789182f9-1afa-448b-9f30-ecf5d407ffd3",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468cbd82-fd1e-47ea-a776-df816b006483",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_kwargs = dict(\n",
    "    root=dataset_root,\n",
    "    block_size=block_size,\n",
    ")\n",
    "\n",
    "train_set = TinyShakespeareDataset(train=True, **dataset_kwargs)\n",
    "val_set = TinyShakespeareDataset(train=False, **dataset_kwargs)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size)\n",
    "train_iter = iter(train_loader)\n",
    "\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "val_iter = iter(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa564731-4d5a-434f-9ed9-d24e09452371",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f100807-c898-48f3-8a35-3dae5999502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PicoGPT(\n",
    "    vocab_size=train_set.vocab_size,\n",
    "    embed_dim=embed_dim,\n",
    "    num_heads=num_heads,\n",
    "    block_size=block_size,\n",
    "    dropout=dropout,\n",
    "    num_layers=num_layers,\n",
    "    bias=bias,\n",
    "    widening_factor=widening_factor,\n",
    ")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a89551fc-bac9-438c-b5e4-c7f055e89a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    params=model.parameters(),\n",
    "    lr=lr,\n",
    "    betas=betas,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aeac78-e980-4daa-b2e8-a82032d1a191",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba93672d-7d6c-4cc8-9ab0-9285c9cf5c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate(\n",
    "    model: PicoGPT,\n",
    "    data_iter, \n",
    "    num_batches: int,\n",
    "    device: torch.device\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    loss_sum = 0\n",
    "    for _ in range(num_batches):\n",
    "        x, y = next(data_iter)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        _, loss = model(x, y)\n",
    "        loss_sum += loss.item()\n",
    "    return loss_sum / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f2ed2c6-072e-43a3-bb9c-36425827c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: PicoGPT,\n",
    "    data_iter,\n",
    "    optimizer,\n",
    "    device: torch.device,\n",
    "    grad_clip_value: float,\n",
    ") -> None:\n",
    "    \"\"\"single training step\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    x, y = next(data_iter)\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    _, loss = model(input=x, target=y)\n",
    "    clip_grad_norm_(model.parameters(), grad_clip_value)\n",
    "    loss.backward()\n",
    "    optimizer.step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce8e496-4ecf-4343-b7b9-7736dfd94ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_kwargs = dict(\n",
    "    model=model,\n",
    "    num_batches=num_val_batches,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "start_id = train_set.encode('\\n')\n",
    "x_start = torch.tensor(start_id, dtype=torch.int64, device=device).unsqueeze(0)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "for step in range(0, max_training_steps + 1):\n",
    "    if step > 0:\n",
    "        train(\n",
    "            model=model,\n",
    "            data_iter=train_iter,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "            grad_clip_value=grad_clip_value,\n",
    "        )\n",
    "\n",
    "    if (step % val_interval == 0):\n",
    "        train_loss = validate(data_iter=train_iter, **validate_kwargs)\n",
    "        val_loss = validate(data_iter=val_iter, **validate_kwargs)\n",
    "        elapsed_time = (time.time() - start_time) / 60\n",
    "        y = model.generate(\n",
    "            x_start, \n",
    "            max_new_tokens, \n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "        )\n",
    "        \n",
    "    print(f'ðŸš€ðŸš€ðŸš€ {step=: >12_d} ({elapsed_time=:.1f} min): {train_loss=:.6f} {val_loss=:.6f}')\n",
    "        print(''.join(train_set.decode(y.tolist()[0])))\n",
    "        print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc38d77-aad5-4b26-8ad7-6d3dbab00aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lec-24-2-dl",
   "language": "python",
   "name": "lec-24-2-dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
